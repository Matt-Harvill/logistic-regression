{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_banknote_authentication.csv')\n",
    "data = np.array(data)\n",
    "# print(data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (4, 1028)\n",
      "Output Shape: (1, 1028)\n"
     ]
    }
   ],
   "source": [
    "X, y = data[:,0:-1], data[:,-1].reshape(-1,1)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.25, random_state=23)\n",
    "X_train, X_dev, y_train, y_dev  = X_train.T, X_dev.T, y_train.T, y_dev.T\n",
    "print(f'Input Shape: {X_train.shape}\\nOutput Shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4\n",
      "Number of examples: 1028\n"
     ]
    }
   ],
   "source": [
    "# Number of features\n",
    "n = X_train.shape[0]\n",
    "# Number of examples\n",
    "m = X_train.shape[1]\n",
    "print(f\"Number of features: {n}\\nNumber of examples: {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid helper function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training parameters W and b\n",
    "def initialize_params():\n",
    "    W = np.random.randn(1,n)\n",
    "    b = 0\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "def forward_prop(X, W, b):\n",
    "    z = W @ X + b\n",
    "    y_hat = sigmoid(z)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cost (negative log likelihood)\n",
    "def compute_cost(y_hat, y):\n",
    "    epsilon = 1e-8\n",
    "    J = np.sum(- (y * np.log(y_hat + epsilon)) - ((1 - y) * np.log(1 - y_hat + epsilon)))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprop pass\n",
    "def backprop(y, y_hat, X):\n",
    "    dJ__dy_hat = (-y / y_hat) + (1 - y)/(1 - y_hat)\n",
    "    dy_hat__dz = y_hat * (1 - y_hat)\n",
    "    dz__dw = X\n",
    "    dz__db = 1\n",
    "\n",
    "    dJ__dw = (dJ__dy_hat * dy_hat__dz) @ dz__dw.T / m\n",
    "    dJ__db = np.sum(dJ__dy_hat * dy_hat__dz) * dz__db / m\n",
    "\n",
    "    return dJ__dw, dJ__db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters\n",
    "def update_params(W, b, dJdW, dJdb, alpha):\n",
    "    W = W - alpha * dJdW\n",
    "    b = b - alpha * dJdb\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression classifier from pieces above\n",
    "def logistic_regression(X, y, num_iterations=1000, print_stage=100, alpha=0.01):\n",
    "\n",
    "    W, b = initialize_params()\n",
    "\n",
    "    for i in range(num_iterations + 1):\n",
    "\n",
    "        y_hat = forward_prop(X, W, b)\n",
    "        J = compute_cost(y_hat, y)\n",
    "        if i % print_stage == 0:\n",
    "            print(f'Iter {i} cost: {J}')\n",
    "        dJdW, dJdb = backprop(y, y_hat, X)\n",
    "        W, b = update_params(W, b, dJdW, dJdb, alpha)\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 cost: 862.4545904654178\n",
      "Iter 100 cost: 516.6193471955128\n",
      "Iter 200 cost: 371.80030839714067\n",
      "Iter 300 cost: 317.6968003771568\n",
      "Iter 400 cost: 295.63771592293574\n",
      "Iter 500 cost: 283.20688281264256\n",
      "Iter 600 cost: 273.9446893030025\n",
      "Iter 700 cost: 265.9874289370192\n",
      "Iter 800 cost: 258.7372425448183\n",
      "Iter 900 cost: 251.97449927460195\n",
      "Iter 1000 cost: 245.6038815793248\n",
      "Iter 1100 cost: 239.57485365916244\n",
      "Iter 1200 cost: 233.854708925655\n",
      "Iter 1300 cost: 228.4187938821\n",
      "Iter 1400 cost: 223.24671399891577\n",
      "Iter 1500 cost: 218.32073607918022\n",
      "Iter 1600 cost: 213.6250383685114\n",
      "Iter 1700 cost: 209.14530701552502\n",
      "Iter 1800 cost: 204.8684851271897\n",
      "Iter 1900 cost: 200.7825963226932\n",
      "Iter 2000 cost: 196.87660955425198\n",
      "Iter 2100 cost: 193.14032994616468\n",
      "Iter 2200 cost: 189.56430790972553\n",
      "Iter 2300 cost: 186.13976210516353\n",
      "Iter 2400 cost: 182.85851340320826\n",
      "Iter 2500 cost: 179.71292783338663\n",
      "Iter 2600 cost: 176.6958669984606\n",
      "Iter 2700 cost: 173.80064475660984\n",
      "Iter 2800 cost: 171.02098920182505\n",
      "Iter 2900 cost: 168.35100914516227\n",
      "Iter 3000 cost: 165.78516443408068\n",
      "Iter 3100 cost: 163.3182395549463\n",
      "Iter 3200 cost: 160.94532005175788\n",
      "Iter 3300 cost: 158.66177136681176\n",
      "Iter 3400 cost: 156.46321976961966\n",
      "Iter 3500 cost: 154.3455350912846\n",
      "Iter 3600 cost: 152.30481502452332\n",
      "Iter 3700 cost: 150.3373707859404\n",
      "Iter 3800 cost: 148.43971396809332\n",
      "Iter 3900 cost: 146.6085444351697\n",
      "Iter 4000 cost: 144.84073913841615\n",
      "Iter 4100 cost: 143.1333417463861\n",
      "Iter 4200 cost: 141.48355300107872\n",
      "Iter 4300 cost: 139.88872172453753\n",
      "Iter 4400 cost: 138.3463364118188\n",
      "Iter 4500 cost: 136.85401735572955\n",
      "Iter 4600 cost: 135.40950925665322\n",
      "Iter 4700 cost: 134.01067427735416\n",
      "Iter 4800 cost: 132.65548550809862\n",
      "Iter 4900 cost: 131.3420208119261\n",
      "Iter 5000 cost: 130.06845702360812\n",
      "Iter 5100 cost: 128.83306447888253\n",
      "Iter 5200 cost: 127.63420185306191\n",
      "Iter 5300 cost: 126.47031129018647\n",
      "Iter 5400 cost: 125.33991380560794\n",
      "Iter 5500 cost: 124.24160494631917\n",
      "Iter 5600 cost: 123.1740506945445\n",
      "Iter 5700 cost: 122.13598360112415\n",
      "Iter 5800 cost: 121.1261991360995\n",
      "Iter 5900 cost: 120.14355224466772\n",
      "Iter 6000 cost: 119.18695409734732\n",
      "Iter 6100 cost: 118.25536902379906\n",
      "Iter 6200 cost: 117.34781162029586\n",
      "Iter 6300 cost: 116.46334402134268\n",
      "Iter 6400 cost: 115.60107332641819\n",
      "Iter 6500 cost: 114.76014917325563\n",
      "Iter 6600 cost: 113.93976144950265\n",
      "Iter 6700 cost: 113.13913813500093\n",
      "Iter 6800 cost: 112.35754326731377\n",
      "Iter 6900 cost: 111.59427502349978\n",
      "Iter 7000 cost: 110.84866391148604\n",
      "Iter 7100 cost: 110.12007106473905\n",
      "Iter 7200 cost: 109.40788663426089\n",
      "Iter 7300 cost: 108.71152827225447\n",
      "Iter 7400 cost: 108.03043970210868\n",
      "Iter 7500 cost: 107.36408936964528\n",
      "Iter 7600 cost: 106.71196917084998\n",
      "Iter 7700 cost: 106.07359325157901\n",
      "Iter 7800 cost: 105.44849687498738\n",
      "Iter 7900 cost: 104.83623535266982\n",
      "Iter 8000 cost: 104.23638303573767\n",
      "Iter 8100 cost: 103.64853236227646\n",
      "Iter 8200 cost: 103.07229295783743\n",
      "Iter 8300 cost: 102.50729078581578\n",
      "Iter 8400 cost: 101.95316734475767\n",
      "Iter 8500 cost: 101.40957890981342\n",
      "Iter 8600 cost: 100.87619581572484\n",
      "Iter 8700 cost: 100.35270177889194\n",
      "Iter 8800 cost: 99.83879325621432\n",
      "Iter 8900 cost: 99.33417883854253\n",
      "Iter 9000 cost: 98.83857867670858\n",
      "Iter 9100 cost: 98.35172393822765\n",
      "Iter 9200 cost: 97.87335629288138\n",
      "Iter 9300 cost: 97.40322742550313\n",
      "Iter 9400 cost: 96.94109857438744\n",
      "Iter 9500 cost: 96.48674009384445\n",
      "Iter 9600 cost: 96.03993103951007\n",
      "Iter 9700 cost: 95.60045877510771\n",
      "Iter 9800 cost: 95.16811859943812\n",
      "Iter 9900 cost: 94.742713392447\n",
      "Iter 10000 cost: 94.32405327929266\n"
     ]
    }
   ],
   "source": [
    "W, b = logistic_regression(X_train, y_train, num_iterations=10000, alpha=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y, y_preds):\n",
    "    total = y_preds.shape[1]\n",
    "    correct = np.sum(abs(y_preds - y) < 0.5)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set accuracy: 0.9795918367346939\n"
     ]
    }
   ],
   "source": [
    "y_dev_preds = forward_prop(X_dev, W, b)\n",
    "\n",
    "accuracy = compute_accuracy(y_dev, y_dev_preds)\n",
    "print(f'Dev set accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3c37e7769e69d88f560728274ac31117419b08426e8f556e7d6b1fc46089862"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
