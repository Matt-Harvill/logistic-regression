{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_banknote_authentication.csv')\n",
    "data = np.array(data)\n",
    "# print(data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (4, 1028)\n",
      "Output Shape: (1, 1028)\n"
     ]
    }
   ],
   "source": [
    "X, y = data[:,0:-1], data[:,-1].reshape(-1,1)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.25, random_state=23)\n",
    "X_train, X_dev, y_train, y_dev  = X_train.T, X_dev.T, y_train.T, y_dev.T\n",
    "print(f'Input Shape: {X_train.shape}\\nOutput Shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4\n",
      "Number of examples: 1028\n"
     ]
    }
   ],
   "source": [
    "# Number of features\n",
    "n = X_train.shape[0]\n",
    "# Number of examples\n",
    "m = X_train.shape[1]\n",
    "print(f\"Number of features: {n}\\nNumber of examples: {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid helper function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training parameters W and b\n",
    "def initialize_params():\n",
    "    W = np.random.randn(1,n)\n",
    "    b = 0\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "def forward_prop(X, W, b):\n",
    "    z = W @ X + b\n",
    "    y_hat = sigmoid(z)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cost (negative log likelihood)\n",
    "def compute_cost(y_hat, y):\n",
    "    epsilon = 1e-8\n",
    "    J = np.sum(- (y * np.log(y_hat + epsilon)) - ((1 - y) * np.log(1 - y_hat + epsilon)))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprop pass\n",
    "def backprop(y, y_hat, X):\n",
    "    dJ__dy_hat = (-y / y_hat) + (1 - y)/(1 - y_hat)\n",
    "    dy_hat__dz = y_hat * (1 - y_hat)\n",
    "    dz__dw = X\n",
    "    dz__db = 1\n",
    "\n",
    "    dJ__dw = (dJ__dy_hat * dy_hat__dz) @ dz__dw.T / m\n",
    "    dJ__db = np.sum(dJ__dy_hat * dy_hat__dz) * dz__db / m\n",
    "\n",
    "    return dJ__dw, dJ__db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters\n",
    "def update_params(W, b, dJdW, dJdb, alpha):\n",
    "    W = W - alpha * dJdW\n",
    "    b = b - alpha * dJdb\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression classifier from pieces above\n",
    "def logistic_regression(X, y, num_iterations=1000, print_stage=100, alpha=0.01):\n",
    "\n",
    "    W, b = initialize_params()\n",
    "\n",
    "    for i in range(num_iterations + 1):\n",
    "\n",
    "        y_hat = forward_prop(X, W, b)\n",
    "        J = compute_cost(y_hat, y)\n",
    "        if i % print_stage == 0:\n",
    "            print(f'Iter {i} cost: {J}')\n",
    "        dJdW, dJdb = backprop(y, y_hat, X)\n",
    "        W, b = update_params(W, b, dJdW, dJdb, alpha)\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 cost: 4924.234155791664\n",
      "Iter 100 cost: 4479.5190673360685\n",
      "Iter 200 cost: 4040.919176682465\n",
      "Iter 300 cost: 3608.8191953873984\n",
      "Iter 400 cost: 3193.363718386354\n",
      "Iter 500 cost: 2805.312690939786\n",
      "Iter 600 cost: 2449.8245970559747\n",
      "Iter 700 cost: 2130.5156819258755\n",
      "Iter 800 cost: 1850.2460008387534\n",
      "Iter 900 cost: 1611.2512559130378\n",
      "Iter 1000 cost: 1414.6408620599063\n",
      "Iter 1100 cost: 1258.6242277258352\n",
      "Iter 1200 cost: 1137.4864157367224\n",
      "Iter 1300 cost: 1043.210259872596\n",
      "Iter 1400 cost: 968.1521323121184\n",
      "Iter 1500 cost: 906.3673720538825\n",
      "Iter 1600 cost: 853.6926306605211\n",
      "Iter 1700 cost: 807.4058464369343\n",
      "Iter 1800 cost: 765.8030470941123\n",
      "Iter 1900 cost: 727.8342788737154\n",
      "Iter 2000 cost: 692.8474898265405\n",
      "Iter 2100 cost: 660.4267527285074\n",
      "Iter 2200 cost: 630.2946396597918\n",
      "Iter 2300 cost: 602.2540347832397\n",
      "Iter 2400 cost: 576.15347803513\n",
      "Iter 2500 cost: 551.866635690185\n",
      "Iter 2600 cost: 529.2804340464312\n",
      "Iter 2700 cost: 508.2886027962688\n",
      "Iter 2800 cost: 488.788588647905\n",
      "Iter 2900 cost: 470.68049062718455\n",
      "Iter 3000 cost: 453.86710270667777\n",
      "Iter 3100 cost: 438.25445679602393\n",
      "Iter 3200 cost: 423.7524906754468\n",
      "Iter 3300 cost: 410.27563650418926\n",
      "Iter 3400 cost: 397.74324233999266\n",
      "Iter 3500 cost: 386.0798099729489\n",
      "Iter 3600 cost: 375.215068785669\n",
      "Iter 3700 cost: 365.0839192472463\n",
      "Iter 3800 cost: 355.6262809286271\n",
      "Iter 3900 cost: 346.78687543632793\n",
      "Iter 4000 cost: 338.51496842617803\n",
      "Iter 4100 cost: 330.7640888671784\n",
      "Iter 4200 cost: 323.491738733294\n",
      "Iter 4300 cost: 316.65910243270105\n",
      "Iter 4400 cost: 310.2307624018841\n",
      "Iter 4500 cost: 304.1744251872469\n",
      "Iter 4600 cost: 298.46066081276217\n",
      "Iter 4700 cost: 293.0626571303807\n",
      "Iter 4800 cost: 287.9559900524159\n",
      "Iter 4900 cost: 283.1184099872737\n",
      "Iter 5000 cost: 278.52964438213\n",
      "Iter 5100 cost: 274.171215976673\n",
      "Iter 5200 cost: 270.02627616136056\n",
      "Iter 5300 cost: 266.0794526905953\n",
      "Iter 5400 cost: 262.3167109102129\n",
      "Iter 5500 cost: 258.7252276078883\n",
      "Iter 5600 cost: 255.29327657527196\n",
      "Iter 5700 cost: 252.01012497451003\n",
      "Iter 5800 cost: 248.8659396233265\n",
      "Iter 5900 cost: 245.85170234717683\n",
      "Iter 6000 cost: 242.95913359018573\n",
      "Iter 6100 cost: 240.18062352545905\n",
      "Iter 6200 cost: 237.50916995738504\n",
      "Iter 6300 cost: 234.9383223617356\n",
      "Iter 6400 cost: 232.4621314622545\n",
      "Iter 6500 cost: 230.07510379385508\n",
      "Iter 6600 cost: 227.77216075178023\n",
      "Iter 6700 cost: 225.54860167257368\n",
      "Iter 6800 cost: 223.40007053616245\n",
      "Iter 6900 cost: 221.32252591861018\n",
      "Iter 7000 cost: 219.31221386212525\n",
      "Iter 7100 cost: 217.36564336276936\n",
      "Iter 7200 cost: 215.4795642071074\n",
      "Iter 7300 cost: 213.65094691695333\n",
      "Iter 7400 cost: 211.8769645865592\n",
      "Iter 7500 cost: 210.15497641928195\n",
      "Iter 7600 cost: 208.4825127911345\n",
      "Iter 7700 cost: 206.85726168689314\n",
      "Iter 7800 cost: 205.2770563707762\n",
      "Iter 7900 cost: 203.7398641683224\n",
      "Iter 8000 cost: 202.24377624914007\n",
      "Iter 8100 cost: 200.7869983118422\n",
      "Iter 8200 cost: 199.36784208286264\n",
      "Iter 8300 cost: 197.98471755010553\n",
      "Iter 8400 cost: 196.63612586062652\n",
      "Iter 8500 cost: 195.3206528189018\n",
      "Iter 8600 cost: 194.03696292878914\n",
      "Iter 8700 cost: 192.78379392813173\n",
      "Iter 8800 cost: 191.55995177016297\n",
      "Iter 8900 cost: 190.36430601051956\n",
      "Iter 9000 cost: 189.19578556281706\n",
      "Iter 9100 cost: 188.05337478944523\n",
      "Iter 9200 cost: 186.93610989754887\n",
      "Iter 9300 cost: 185.84307561311857\n",
      "Iter 9400 cost: 184.77340210875792\n",
      "Iter 9500 cost: 183.726262163064\n",
      "Iter 9600 cost: 182.7008685316791\n",
      "Iter 9700 cost: 181.69647151196813\n",
      "Iter 9800 cost: 180.7123566849868\n",
      "Iter 9900 cost: 179.7478428199319\n",
      "Iter 10000 cost: 178.802279927644\n"
     ]
    }
   ],
   "source": [
    "W, b = logistic_regression(X_train, y_train, num_iterations=10000, alpha=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y, y_preds):\n",
    "    total = y_preds.shape[1]\n",
    "    correct = np.sum(abs(y_preds - y) < 0.5)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set accuracy: 0.9504373177842566\n"
     ]
    }
   ],
   "source": [
    "y_dev_preds = forward_prop(X_dev, W, b)\n",
    "\n",
    "accuracy = compute_accuracy(y_dev, y_dev_preds)\n",
    "print(f'Dev set accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3c37e7769e69d88f560728274ac31117419b08426e8f556e7d6b1fc46089862"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
